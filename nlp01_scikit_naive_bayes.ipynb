{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit naive bayes\n",
    "\n",
    "15 June 2017. 양철웅\n",
    "\n",
    "\n",
    "\n",
    "`scikit-learn` 라이브러리를 이용하여 텍스트 파일에 대한 카테고리 분석을 진행해본다.\n",
    "Naive Bayes 분석을 이용하는데 왜냐하면 (1) 텍스트 분석에서 Naive Bayes는 웬만한 Deep Learning보다 더 효율적이며, (2) 또한 그로 인해 baseline 알고리즘으로써의 역할을 하기 때문이다. Naive Bayes분석보다 못 한 알고리즘은 버려야한다.\n",
    "\n",
    "이 문서는 http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html 를 나름대로 정리한 것이다.\n",
    "\n",
    "## 준비사항\n",
    "\n",
    "### 라이브러리 설치\n",
    "우선 `scikit-learn` 라이브러리를 설치한다. 필요에 따라서 `libblas-dev liblapack-dev gfortran`를 먼저 설치해야 할 수 있다.\n",
    "```\n",
    "pip install -U scikit-learn[alldeps]\n",
    "```\n",
    "\n",
    "### 데이터셋\n",
    "20,000 뉴스그룹 문서로 이루어진 데이터셋인 \"Twenty Newsgroups\"을 사용한다. 20개의 서로 다른 뉴스그룹에서 발췌한 문서이다. 이 데이터셋은 텍스트 분류 및 클러스터링등의 기계학습 실험에서 많이 사용되었다. 해당 데이터셋은 API를 이용하여 자동으로 다운받을 수 있다. http://qwone.com/~jason/20Newsgroups/ 에서 수동으로 다운받을 수도 있다.\n",
    "\n",
    "## 코드\n",
    "### 데이터셋 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length=11314\n",
      "target_names=['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "rec.autos\n",
      "[ 7  4  4  1 14 16 13  3  2  4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# 우선 테스트로 4개의 뉴스그룹만 사용\n",
    "# categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "categories = None # all group\n",
    "\n",
    "# 해당 카테고리에 매칭되는 파일을 읽어온다. 읽어올 때 shuffle을 수행한다.\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "print \"dataset length=%d\" % len(twenty_train.data)\n",
    "print \"target_names=%s\" % twenty_train.target_names\n",
    "#first four lines of the first record\n",
    "print \"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])\n",
    "#target (==y). 해당 레코드가 속한 카테고리 id이다. 이를 이용하여 supervised learning을 진행한다.\n",
    "print twenty_train.target_names[twenty_train.target[0]]\n",
    "print twenty_train.target[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 전처리 \n",
    "BoW (Bag of words)를 만든다. 방법은 다음과 같다.\n",
    "- 각 단어로 dictionary를 만든다.\n",
    "- 각 문서 `#i`에 대하여 각 단어 `w`의 빈도수를 세어 그 수를 `X[i,j]`에 저장한다. `j`는 `w`의 dictionary index이다.\n",
    "\n",
    "`n_feature`는 모든 단어의 수이며 100K을 넘게 된다. 문서의 수가 10K를 넘는 경우 `X`의 저장을 위해서는 1G \\* 4 bytes (float32) = __4GB__ 메모리를 요구한다. \n",
    "\n",
    "`X`를 sparse 자료구조를 이용하면 메모리 소모양이 감소한다. 따라서 `scipy.sparse` 행렬을 사용한다.\n",
    "\n",
    "영문 stopword (a,the,..)등의 제거, 토큰화, n-gram기능등을 위해 `scikit-learn`의 `CountVectorizer`를 이용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n",
      "27366\n",
      "(11314, 130107)\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer(stop_words=None) # None, 'english', or custom list\n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "print X_train_counts.shape  # 문서수 x 총단어수\n",
    "print count_vect.vocabulary_.get(u'algorithm') # 'algorithm'의 출현횟수\n",
    "\n",
    "# occurrence => term frequency\n",
    "# 또한 많이 나오는 term에 대해서는 weight를 줄인다: TF-IDF: Term Frequency x Inverse Docuement Frequency\n",
    "# idf 안쓰고 싶으면 TfidfTransformer(use_idf=False)를 쓴다.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print X_train_tfidf.shape\n",
    "print len(twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습\n",
    "multinomial (멀티 카테고리) naive bayes를 이용하여 학습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target) # classifier\n",
    "\n",
    "# test\n",
    "def test1(clf):\n",
    "    foo = ['There is no god in the world', 'OpenGL runs on GPU', 'aspirin is a cheap pill']\n",
    "    X_foo_counts = count_vect.transform(foo)\n",
    "    X_foo_tfidf = tfidf_transformer.transform(X_foo_counts)\n",
    "    predicted = clf.predict(X_foo_tfidf)\n",
    "    for doc, category in zip(foo, predicted):\n",
    "        print '%r => %s' % (doc, twenty_train.target_names[category])\n",
    "# test1(clf)\n",
    "\n",
    "# pipelining vectorizer => transformer => classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "_ = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy = 0.773898\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# training set이 아닌 별도의 test set을 가지고 검증한다.\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                categories = categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print \"naive bayes accuracy = %f\" % np.mean(predicted == twenty_test.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계\n",
    "- precision = True Positive / (True Positive + False Positive). 검색된 문서들 중 관련있는 문서의 비율\n",
    "- recall = True Positive / (True Positive + False Negative). 관련있는 문서들 중 검색된 문서의 비율\n",
    "- f1-score = 2 * precision * recall / (precision + recall). precision과 recall의 조화평균\n",
    "- support = The number of occurrences of each label in y_true\n",
    "- confusion matrix - 실제 클래스(row)와 예측클래스(column)간의 관계이다. 아래를 보면 기사들이 꽤 sci.crypt, soc.religion.christian으로 오분류되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "             avg / total       0.82      0.77      0.77      7532\n",
      "\n",
      "[[166   0   0   1   0   1   0   0   1   1   1   3   0   6   3 123   4   8\n",
      "    0   1]\n",
      " [  1 252  15  12   9  18   1   2   1   5   2  41   4   0   6  15   4   1\n",
      "    0   0]\n",
      " [  0  14 258  45   3   9   0   2   1   3   2  25   1   0   6  23   2   0\n",
      "    0   0]\n",
      " [  0   5  11 305  17   1   3   6   1   0   2  19  13   0   5   3   1   0\n",
      "    0   0]\n",
      " [  0   3   8  23 298   0   3   8   1   3   1  16   8   0   2   8   3   0\n",
      "    0   0]\n",
      " [  1  21  17  13   2 298   1   0   1   1   0  23   0   1   4  10   2   0\n",
      "    0   0]\n",
      " [  0   1   3  31  12   1 271  19   4   4   6   5  12   6   3   9   3   0\n",
      "    0   0]\n",
      " [  0   1   0   3   0   0   4 364   3   2   2   4   1   1   3   3   4   0\n",
      "    1   0]\n",
      " [  0   0   0   1   0   0   2  10 371   0   0   4   0   0   0   8   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   0   4   0 357  22   0   0   0   2   9   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   4 387   1   0   0   1   5   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   0   1   1   3   0   0   0 383   1   0   0   3   1   0\n",
      "    0   0]\n",
      " [  0   4   2  17   5   0   2   8   7   1   2  78 235   3  11  15   2   1\n",
      "    0   0]\n",
      " [  2   3   0   1   1   3   1   0   2   3   4  11   5 292   6  52   6   4\n",
      "    0   0]\n",
      " [  0   2   0   1   0   3   0   2   1   0   1   6   1   2 351  19   4   0\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   0   1   0   0   0   0   1   2 392   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   2   0   1   1   0  10   0   0   1   6 341   1\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1   0   2   0   0   0  24   3 344\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   1   0   0   1  11   0   1   7  35 118   5\n",
      "  129   0]\n",
      " [ 33   2   0   0   0   0   0   0   0   1   1   3   0   4   4 131  29   5\n",
      "    3  35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print metrics.classification_report(twenty_test.target, predicted,\n",
    "                                    target_names=twenty_test.target_names)\n",
    "print metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고: SVM(서포트 벡터 머신) classifier와의 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy = 0.823818\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.72      0.72       319\n",
      "           comp.graphics       0.80      0.70      0.74       389\n",
      " comp.os.ms-windows.misc       0.73      0.76      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.70      0.70       392\n",
      "   comp.sys.mac.hardware       0.83      0.81      0.82       385\n",
      "          comp.windows.x       0.83      0.77      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.92      0.89      0.91       396\n",
      "         rec.motorcycles       0.92      0.96      0.94       398\n",
      "      rec.sport.baseball       0.89      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.83      0.96      0.89       396\n",
      "         sci.electronics       0.83      0.60      0.70       393\n",
      "                 sci.med       0.87      0.86      0.86       396\n",
      "               sci.space       0.84      0.96      0.89       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.40      0.55       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# SGDClassifier: Stochastic Gradient Descent Classifier\n",
    "# This implementation works with data represented as dense or sparse arrays of \n",
    "# floating point values for the features. The model it fits can be controlled \n",
    "# with the loss parameter; by default, it fits a linear support vector machine (SVM).\n",
    "svm_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                          alpha=1e-3, n_iter=5,\n",
    "                                          random_state=42))])\n",
    "_ = svm_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_svm = svm_clf.predict(docs_test)\n",
    "print \"SVM accuracy = %f\" % np.mean(predicted_svm == twenty_test.target)\n",
    "\n",
    "print metrics.classification_report(twenty_test.target, predicted_svm,\n",
    "                                    target_names=twenty_test.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고2: 그리드 검색을 이용한 하이퍼파라메터 튜닝\n",
    "학습시에 학습 파라메터(hyperparameter)를 여러가지로 변경하면서 최적값을 찾아야 하는데, sci-kit에서는 그를 위하여 그리드 검색을 제공한다. 하이퍼파라메터별로 값들을 지정하면 그 조합대로 테스트를 해 보며 최적값을 찾아준다.\n",
    "여기서는 SVM classifier를 이용할 경우, ngram값 (1-gram, 2-gram), idf유무, alpha값의 조합을 테스트하는 예를 들어본다. 모두 2\\*2\\*2 = 8개의 조합을 테스트하게된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"God is love\" is group soc.religion.christian\n",
      "0.6025\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1,1), (1,2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3)}\n",
    "gs_clf = GridSearchCV(svm_clf, parameters, n_jobs=-1) # n_jobs is the number of CPU cores\n",
    "_ = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])\n",
    "\n",
    "print \"\\\"God is love\\\" is group %s\" % twenty_train.target_names[gs_clf.predict(['God is love'])[0]]\n",
    "# object's `best_core_` and `best_params_` attributes store the best mean score \n",
    "# and the parameter settings\n",
    "print gs_clf.best_score_\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print \"%s: %r\" % (param_name, gs_clf.best_params_[param_name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
